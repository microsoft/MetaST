{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.33\n",
      "Library configuration succeeded\n",
      "https://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/4a66f470-dd54-4c5e-bd19-8cb65a426003/resourceGroups/AML_Playground/providers/Microsoft.MachineLearningServices/workspaces/Teams_ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id = \"4a66f470-dd54-4c5e-bd19-8cb65a426003\"\n",
    "resource_group  = \"AML_Playground\"\n",
    "workspace_name  = \"Teams_ws\"\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    ws.write_config()\n",
    "    print('Library configuration succeeded')\n",
    "    print('https://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource' + ws.get_details()['id'])\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "cluster_name = \"p100cluster\"\n",
    "\n",
    "\n",
    "compute_target = ws.compute_targets[cluster_name]\n",
    "print('Found existing compute target.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for Teams_slot_model\\bert_config.json\n",
      "Target already exists. Skipping upload for Teams_slot_model\\pytorch_model.bin\n",
      "Target already exists. Skipping upload for Teams_slot_model\\vocab.txt\n",
      "Target already exists. Skipping upload for Communication_slot_model_unsupervised\\bert_config.json\n",
      "Target already exists. Skipping upload for Communication_slot_model_unsupervised\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_9933ac0ddaa9470193e54d7496725aa9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for Communication_slot_model_unsupervised\\vocab.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\BIO-tags.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\comm_train_prod.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_62d59b6cc94c46a7bd07f9105f2d5e7c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for datasets/Teams_communication\\Target_set_message_new_conll.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\test.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\test_blind_old.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\test_nonormal.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train_19k_only.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train_legacy_1m.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train_positive_generated.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train_teams.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\train_valid_oct.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\valid.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\valid_aug.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\valid_sep.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\valid_valid.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\generated_data\\communication_message_generated_contact.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\generated_data\\communication_message_generated_no_contact.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\raequery_for_prod_with_target.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_contact_message_generated.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_expanision-outputs.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_for_prod.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_for_prod_from_valid_nov.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_for_prod_from_valid_nov_normalized.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_for_prod_with_civ.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_from_civ.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_merged.txt\n",
      "Target already exists. Skipping upload for datasets/Teams_communication\\raw_generated_data\\rawquery_no_contact_message_generated.txt\n",
      "Target already exists. Skipping upload for Communication_slot_model_fine-tuned\\bert_config.json\n",
      "Target already exists. Skipping upload for Communication_slot_model_fine-tuned\\eval_results.txt\n",
      "Target already exists. Skipping upload for Communication_slot_model_fine-tuned\\model_config.json\n",
      "Target already exists. Skipping upload for Communication_slot_model_fine-tuned\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_b26a7627609c40049df3fe41c281e7b3\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "#upload local model\n",
    "model_path_on_datastore = 'Teams_slot_model' #cased model,vocab is too small? Do not have frequent word like common\n",
    "ds_model = ds.path(model_path_on_datastore)\n",
    "ds.upload(src_dir=r'D:\\dl_repo\\Tagging_data\\bert-base-English-cased-pytorch',\n",
    "          target_path= model_path_on_datastore,\n",
    "          overwrite=False,\n",
    "          show_progress=True)\n",
    "print(ds_model.as_mount())\n",
    "#upload unsupervised local model\n",
    "model_path_on_datastore = 'Communication_slot_model_unsupervised' #cased model,vocab is too small? Do not have frequent word like common\n",
    "ds_model_unsupervised = ds.path(model_path_on_datastore)\n",
    "ds.upload(src_dir=r'D:\\dl_repo\\Data_model\\Communication_unsupervised',\n",
    "          target_path= model_path_on_datastore,\n",
    "          overwrite=False,\n",
    "          show_progress=True)\n",
    "print(ds_model_unsupervised.as_mount())\n",
    "#upload local data set\n",
    "path_on_datastore = 'datasets/Teams_communication'\n",
    "ds_data_communication = ds.path(path_on_datastore)\n",
    "ds.upload(src_dir=r'D:\\dl_repo\\Data_model\\Communication_data',\n",
    "          target_path= path_on_datastore,\n",
    "          overwrite=False,\n",
    "          show_progress=True)\n",
    "#upload pre-trained model\n",
    "#TODO: reuse azure blob path in aml\n",
    "model_path_on_datastore = 'Communication_slot_model_fine-tuned' #cased model,vocab is too small? Do not have frequent word like common\n",
    "ds_model_pretrained = ds.path(model_path_on_datastore)\n",
    "ds.upload(src_dir=r'D:\\dl_repo\\Data_model\\Communication_finetuned',\n",
    "          target_path= model_path_on_datastore,\n",
    "          overwrite=False,\n",
    "          show_progress=True)\n",
    "print(ds_model.as_mount())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'Similarity_search' \n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BATCH AI\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "script_params = {\n",
    "    '--corpus_input':ds.path(f'azureml-blobstore-1dd9ddd7-6d52-40ad-8b00-be73cd90fd63/lm_data_civ.txt').as_mount(),\n",
    "    '--query_input':'sample_data/teamsmessage_raw.txt'\n",
    "}\n",
    "\n",
    "estimator10 = PyTorch(source_directory='..', \n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target, \n",
    "                    entry_script='src/sentence_similarity_search.py',\n",
    "                    #pip_packages=['pandas','pytorch-pretrained-bert==0.4.0','seqeval==0.0.5'],\n",
    "                    #pip_packages=['pandas','pytorch-pretrained-bert==0.6.1','seqeval==0.0.5','nltk'],\n",
    "                    pip_packages=['pandas','transformers','pytorch-pretrained-bert==0.6.1','seqeval==0.0.5','nltk','faiss-gpu','sentence-transformers'],\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda9.0-cudnn7-ubuntu16.04\n",
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - pandas\n",
      "  - transformers\n",
      "  - pytorch-pretrained-bert==0.6.1\n",
      "  - seqeval==0.0.5\n",
      "  - nltk\n",
      "  - faiss-gpu\n",
      "  - sentence-transformers\n",
      "  - azureml-defaults\n",
      "  - torch==1.0\n",
      "  - torchvision==0.2.1\n",
      "  - horovod==0.15.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(estimator10.run_config.environment.docker.base_image)\n",
    "print(estimator10.conda_dependencies.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4321d12a6d4d099cdfc733896223b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = experiment.submit(estimator10)\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
